<!DOCTYPE html>
<!-- saved from url=(0034)http://www.cs.toronto.edu/~slwang/ -->
<html><div class="oneNoteWebClipperIsInstalledOnThisBrowser" style="display: none;"></div><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Onkar Krishna</title>
<link href="./src/gly.css" rel="stylesheet" type="text/css">

<script type="text/javascript" async="" src="./src/ga.js"></script><script type="text/javascript" async="" src="./src/ga(1).js"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-543380-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body>

<div class="container"> 
    <div style="text-align: right;">
    Japanese / English
  </div>    
    <table width="95%" border="0" align="center">
      <tbody><tr>
        <td width="20%"><div align="center"><img src="./src/onkar_krishna.jpg" width="150" height="200" align="middle" class="dropshadow1"></div></td>
        <td width="80%"><div align="center">
          <table width="110%" border="0">
            <tbody><tr>
            <td width="10%" height="0" valign="top"></td>
            <td width="81%" valign="top">
              <table width="79%" border="0" align="left">
                <tbody><tr>
                  <td align="left"><span class="textpageheader">Onkar Krishna</span></td>
                </tr>
              </tbody></table></td>
            </tr>
            <tr>
                <td width="10%" height="55" valign="top"> </td>
                <td width="200%" valign="top">
                <p style="line-height:120%">
                  <a href="https://www.hitachi.com/rd/">Intelligent Vision Research Department</a><br>
                  <a href="https://www.hitachi.com/rd/">Hitachi, Ltd. Research & Development Group, Tokyo, Japan</a> <br>Senior Research<br>
                </p>
            <p style="line-height:120%">
             Phone <br> (+81) 80-3409-1020 <br>
                  </p>
              </tr>
                <tr>
            <td width="12%" height="20" valign="top"> Address:</td>
            <td width="150%" valign="top">
                Higashi-Naruse, Isehara-shi, Kanagawa 259-1117
          </tr>
          <tr>
            <td height="1">&nbsp Email:</td>
            <td>onkarkris at gmail.com </td>
          </tr>
          <td width="10%" height="10"> </a></td>
          <td ><a href="./document/CV_onkar.pdf">[Curriculum Vitae]</a></td>
          <td> </td>
         </tbody></table>
        </div></td>
        <td width="10%"><div align="center">
          <table width="100%" border="0">
          </table>
        </div></td>
      </tr>
  </tbody></table>
<hr>
<p><br>
  I am a researcher at <a href="http://www.kecl.ntt.co.jp/english/index.html">NTT Communication Science Laboratories</a> in NTT Corporation</a>. 
  I obtained my PhD in 2018 from <a href="https://www.u-tokyo.ac.jp/en/index.html"> The University of Tokyo, Japan</a>.   
  My general research interest lies in image processing and computer vision. 
  <!--I accept students who already obtained or bring to apply <a href="http://www.mext.go.jp/a_menu/koutou/ryugaku/boshu/1346643.htm"> MEXT</a> scholarship. Please send your resume.<br></p>
  -->
<p class="textsectionheader2">News</p>
<hr>
<p>
</p><ul type="SQUARE">
</li><li>One paper accepted to ACCV 2020. "Adaptive Spotting: Deep Reinforcement Object Search in 3D Point Clouds"</a>. <a href="./document/accv_20.pdf">[Paper]</a>
</li><li>One paper accepted to ICPR 2020. "Translating Adult’s Focus of Attention to Elderly’s"</a>. <a href="./document/ICPR_20.pdf">[Paper]</a>
</li><li>One journal paper accepted to MTAP 2020. "Computational attention model for children, adults and the elderly"</a>. <a href="./document/MTAP2020_onkar.pdf">[Slides]</a>
</li><li>Presented demo of our work in NTT Open House 2020.</a>. <a href="http://www.kecl.ntt.co.jp/openhouse/2020/exhibition19/index_en.html">[English]</a>
<a href="http://www.kecl.ntt.co.jp/openhouse/2020/exhibition19/index.html">[Japanese]</a>
</li><li>One paper accepted to MIRU 2019 (Oral: 28.0%). "Deep Reinforcement Template Matching"</a>. <a href="./document/MIRU_slides.pdf">[Slides]</a>
</li><li>I have presented my work in SSII 2019. "Predicting Focus-of-Attnetion of Eldelry Drivers"</a>. <a href="./document/SSII_fy.pdf">[Flyer]</a> <a href="./document/SSII_poster.pdf">[Poster]</a>
</li><li>One paper accepted to IEEE ICASSP 2019. "Learning Search Path for Region-level Image Matching"</a>. <a href="https://ieeexplore.ieee.org/document/8682714">[Paper]</a> 
</li><li>One paper accepted to 25TH International Conference on Noise and Fluctuations (ICNF 2019)</a>. <a href="https://easychair.org/publications/preprint/xfMT">[EasyChair]</a>
</li><li>One paper accepted to IEEE ICIP 2018. "Billboard Saliency Detection in Street Videos for Adults and Elderly"</a>. <a href="https://ieeexplore.ieee.org/document/8451835">[Paper]</a>
</li><li>One paper accepted to IEEE ICASSP 2018. "Signboard Saliency Detection in Street Videos"</a>. <a href="https://ieeexplore.ieee.org/document/8461773">[Paper]</a>
</li><li>One paper accepted to PLOS ONE 2018. "Gaze distribution analysis and saliency prediction across age groups"</a>. <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0193149">[paper]</a>
</li><li>One paper accepted to ACMMM 2017 for Demo. "MatPlanner: Plan Your Days in Conferences by Resolving Conflicting Events"</a>. <a href="https://dl.acm.org/ft_gateway.cfm?id=3127915&type=pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=9KqxKykBC3o">[Video]</a>
</li><li>One paper accepted to ACM Symposium on Applied Perception (SAP 2017). "Age-adapted Saliency Model with Depth Bias"</a>. <a href="https://dl.acm.org/citation.cfm?id=3119885">[Paper]</a>
</li><li>One paper accepted to Human Vision and Electronic Imaging (HVEI 2017). <a href="https://doi.org/10.2352/ISSN.2470-1173.2017.14.HVEI-148">[Paper]</a>

</li></ul>
<p></p> 
<p class="textsectionheader2">Publications</p><hr>
<table width="100%" border="0">
  <tbody>

    <tr>
      <td width="26%"><img src="./src/accv20.gif" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Adaptive Spotting: Deep Reinforcement Object Search in 3D Point Clouds </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Go Irie, Xiaomeng Wu, Takahito Kawanishi, Kunio Kashino<br>
		ACCV 2020<br>
        <a href="./document/accv_20.pdf">[Paper]</a> <a href="./src/accv-spotlight.mp4">[Spot light]</p></td>
      <td>&nbsp;</td>
    </tr>

     <tr>
      <td width="26%"><img src="./src/icpr20.png" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Translating Adult’s Focus of Attention to Elderly’s </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Go Irie, Takahito Kawanishi, Kunio Kashino, Kiyoharu Aizawa<br>
		ICPR 2020<br>
        <a href="./document/icpr_20.pdf">[Paper]</p></td>
      <td>&nbsp;</td>
    </tr>

    <tr>
      <td width="26%"><img src="./src/tracking_1.gif" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Deep Reinforcement Template Matching </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Go Irie, Xiaomeng Wu, Takahito Kawanishi, Kunio Kashino<br>
		MIRU 2019<br>
        <a href="./document/MIRU_2019_camera.pdf">[Paper]</a> <a href="./document/MIRU_slides.pdf">[Slides]</a> <a href="./document/MIRU19_poster.pdf">[Poster] </p></td>
      <td>&nbsp;</td>
    </tr>

    <tr>
      <td width="26%"><img src="./src/icassp19.JPG" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Learning Search Path for Region-level Image Matching </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Go Irie, Xiaomeng Wu, Takahito Kawanishi, Kunio Kashino<br>
		ICASSP 2019<br>
              <a href="https://ieeexplore.ieee.org/document/8682714">[Paper]</a> <a href="./document/icassp_19_poster.pdf">[Poster]</a> [Code] </p></td>
      <td>&nbsp;</td>
    </tr>

    <tr>
      <td width="26%"><img src="./src/icip2018.png" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Billboard Saliency Detection in Street Videos for Adults and Elderly </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Kiyoharu Aizawa<br>
        ICIP 2018<br>
              <a href="https://ieeexplore.ieee.org/document/8451835">[Paper]</a> <a href="./document/icip_18_poster.pdf">[Poster]</a>  [Dataset]</p></td>
      <td>&nbsp;</td>
    </tr>

    <tr>
      <td width="26%"><img src="./src/icassp_18.png" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Signboard Saliency Detection in Street Videos </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Kiyoharu Aizawa, Saskia Reimerth<br>
        ICASSP 2018<br>
              <a href="https://ieeexplore.ieee.org/document/8461773">[Paper]</a> <a href="./document/icassp_18_poster.pdf">[Poster]</a> [Code] [Dataset] </p></td>
      <td>&nbsp;</td>
    </tr>

    <tr>
      <td width="26%"><img src="./src/pone.PNG" width="240" height="100" class="papericon"></td>
      <td width="4%"> </td>
      <td width="68%"><p class="papertext"><strong>
        Gaze Distribution Analysis and Saliency Prediction Across Age Groups </strong><br>
        <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Andrea Helo, Pia Rämä, Kiyoharu Aizawa<br>
        PLOS ONE 2018<br>
              <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0193149">[Paper]</a>[Dataset]</a> </p></td>
      <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="26%"><img src="./src/acmmm_demo.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>MatPlanner: Plan Your Days in Conferences by Resolving Conflicting Events</strong><br>
      Saemi Choi, <a href="https://onkar.github.io/index.html">Onkar Krishna</a>, Wen-Yu Lee, Kiyoharu Aizawa<br>
      ACMMM Demo 2017<br>
            <a href="https://dl.acm.org/ft_gateway.cfm?id=3127915&type=pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=9KqxKykBC3o">[Video]</a> </p></td>
    <td>&nbsp;</td>
  </tr>

    <tr>
    <td width="26%"><img src="./src/depth.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>Age-adapted Saliency Model with Depth Bias</strong><br>
      <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Kiyoharu Aizawa<br>
        ACM SAP 2017<br>
            <a href="https://dl.acm.org/citation.cfm?id=3119885">[Paper]</a> </p></td>
    <td>&nbsp;</td>
  </tr>

    <tr>
    <td width="26%"><img src="./src/hvei_2017.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>Developmental Changes in Ambient and Focal Visual Processing Strategies</strong><br>
      <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Yamasaki Toshihiko, Andrea Helo, Pia Rämä, Kiyoharu Aizawa<br>
      	Electronic Imaging, Human Vision and Electronic Imaging (HVEI) 2017<br>
            <a href="https://doi.org/10.2352/ISSN.2470-1173.2017.14.HVEI-148">[Paper]</a> </p></td>
    <td>&nbsp;</td>
  </tr>

    <tr>
    <td width="26%"><img src="./src/noise_2.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>Noise Induced Segmentation of Noisy Color Image</strong><br>
      <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, R.K. Jha, A.K. Tiwari, B. Soni<br>
      NCC 2013<br>
            <a href="https://ieeexplore.ieee.org/abstract/document/6487939">[Paper]</a> </p></td>
    <td>&nbsp;</td>
  </tr>

    <tr>
    <td width="26%"><img src="./src/eusipco.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>Dynamic stochastic resonance-based watermark extraction from audio signals in SVD domain</strong><br>
      <strong>Rajib Kumar Jha, <a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Kiyoharu Aizawa<br>
      20th European Signal Processing Conference (EUSIPCO), 2012<br>
            <a href="https://ieeexplore.ieee.org/document/6334139">[Paper]</a></p></td>
    <td>&nbsp;</td>
  </tr>

    <tr>
    <td width="26%"><img src="./src/dwt-svd.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>Dynamic stochastic resonance-based improved watermark extraction in DWT-SVD domain</strong><br>
       <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Rajib Kumar Jha, PK Biswas<br>
      IEEE ICIAS 2012 (Oral)<br>
            <a href="https://ieeexplore.ieee.org/abstract/document/6306091">[Paper]</a></p></td>
    <td>&nbsp;</td>
  </tr>

    <tr>
    <td width="26%"><img src="./src/ncc12.png" width="240" height="100" class="papericon"></td>
    <td width="4%"> </td>
    <td width="68%"><p class="papertext"><strong>Dynamic stochastic resonance-based improved watermark extraction from audio signal</strong><br>
      <strong><a href="https://onkar.github.io/index.html">Onkar Krishna</a></strong>, Rajib Kumar Jha, P.K. Biswas, M. M. Mushrif<br>
      NCC 2012 <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/6176799">[Paper]</a> </p></td>
			
    <td>&nbsp;</td>
  </tr>


 
</tbody></table> 
<br>


<p class="textsectionheader2">COLLABORATIONS AND TALKS</p>
<hr>
<ul>
<li><span style="font-size: medium;"> Visiting Student at Dept. of Brain and Cognitive Sciences MIT, Cambridge, MA</span></li>
<li><span style="font-size: medium;"> Visiting Researcher at Laboratoire Psychologie de la Perception Paris Descartes University, CNRS, Paris, France
</span></li>
<li><span style="font-size: medium;">Researcher Internship at Yokohama Research Lab Hitachi Ltd., Yokohama, Japan
</span></li>
<li><span style="font-size: medium;">Invited talk at Berkeley Artificial Intelligence Research Lab on March 2018.
</span></li>
<li><span style="font-size: medium;">Gave talk on Computational Aspect of Visual perception at Dept. of Brain and Cognitive Sciences, MIT, Cambridge, MA on Feb. 2017.
</span></li>
</ul><br clear="all"><p class="posted"> </p>

<p class="textsectionheader2">Grants</p>
<hr>
<ul>
<li><span style="font-size: medium;">MONBUKAGAKUSHO, Ministry of Education, Culture, Sports, Science, and Technology (MEXT), Japan (for 4 years)</span></li>
<li><span style="font-size: medium;">MHRD, Ministry of Human Resource Development, Government of India (for 2 years)</span></li>
<li><span style="font-size: medium;">JENESYS programme, Industrial visit was fully supportedby Japan Government (for 2 months)</span></li>
<li><span style="font-size: medium;">Takuetsu-daigakuin, The University of Tokyo, Japan (for a month)
</span></li>
</ul><br clear="all"><p class="posted"> </p>

<p class="textsectionheader2">EXTRA-CURRICULAR ACTIVITIES</p>
<hr>
<ul>
<li><span style="font-size: medium;">Vice president of The University of Tokyo Indian Student Association (UTISA)</span></li>
<li><span style="font-size: medium;">Reviewer of TPAMI, CVIU, ICIP, MTAP, CVA, ICPR, MVA, ...
</ul><br clear="all"><p class="posted"> </p>


</div></body></html>
